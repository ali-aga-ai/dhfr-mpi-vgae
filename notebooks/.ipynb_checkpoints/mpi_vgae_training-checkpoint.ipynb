{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the notebook in conda tf env** <br>\n",
    "**Conda activate tf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "# from node2vec import Node2Vec\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:27:33.570440: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-28 23:27:33.634210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-28 23:27:33.634268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-28 23:27:33.635850: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-28 23:27:33.644295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-28 23:27:34.935019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ali/.local/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgae.optimizer import OptimizerAE, OptimizerVAE\n",
    "from vgae.model import GCNModelVAE, GCNModelAE\n",
    "from vgae.preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import scipy.stats as scs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize VGAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC AUC\n",
    "def get_roc_score_vgae(edges_pos, edges_neg, pos_weight, norm, emb=None):\n",
    "    if emb is None:\n",
    "        feed_dict.update({placeholders['dropout']: 0})\n",
    "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds_pos = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds_pos.append(sigmoid(adj_rec[e[0], e[1]])) # predicted score for given edge\n",
    "        pos.append(adj_orig[e[0], e[1]]) # actual value (1)\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]])) # predicted score for given edge\n",
    "        neg.append(adj_orig[e[0], e[1]]) # actual value (0)\n",
    "\n",
    "    preds_all = np.hstack([preds_pos, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    fpr, tpr, _ = roc_curve(labels_all, preds_all)\n",
    "    precision, recall, _ = precision_recall_curve(labels_all, preds_all)\n",
    "    pr_score = auc(recall, precision)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    \n",
    "    # val_loss = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(labels=tf.constant(labels_all), logits=tf.constant(preds_all), pos_weight=pos_weight))\n",
    "    # val_loss = tf.keras.backend.eval(val_loss)\n",
    "\n",
    "    return roc_score, ap_score, fpr, tpr, pr_score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homo sapiens 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ali/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Creating GAE optimizer...\n",
      "Labels shape:  (?,)\n",
      "Preds shape:  (?,)\n",
      "WARNING:tensorflow:From /home/ali/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "CE+KL loss shape:  ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:27:40.325403: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-08-28 23:27:40.325488: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: bitsp-server\n",
      "2025-08-28 23:27:40.325498: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: bitsp-server\n",
      "2025-08-28 23:27:40.325744: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 550.54.15\n",
      "2025-08-28 23:27:40.325791: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 550.54.15\n",
      "2025-08-28 23:27:40.325797: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 550.54.15\n",
      "2025-08-28 23:27:40.377428: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m avg_cost \u001b[38;5;241m=\u001b[39m outs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     90\u001b[0m avg_accuracy \u001b[38;5;241m=\u001b[39m outs[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m roc_curr, ap_curr, fpr, tpr, pr_score, precision, recall \u001b[38;5;241m=\u001b[39m \u001b[43mget_roc_score_vgae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edges_false\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# train_loss_log.append(train_loss_epoch)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# # Evaluate predictions\u001b[39;00m\n\u001b[1;32m     95\u001b[0m roc_curr, ap_curr, fpr, tpr, pr_score, precision, recall \u001b[38;5;241m=\u001b[39m get_roc_score_vgae(val_edges, val_edges_false, pos_weight, norm)\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mget_roc_score_vgae\u001b[0;34m(edges_pos, edges_neg, pos_weight, norm, emb)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m edges_neg:\n\u001b[1;32m     21\u001b[0m     preds_neg\u001b[38;5;241m.\u001b[39mappend(sigmoid(adj_rec[e[\u001b[38;5;241m0\u001b[39m], e[\u001b[38;5;241m1\u001b[39m]])) \u001b[38;5;66;03m# predicted score for given edge\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     neg\u001b[38;5;241m.\u001b[39mappend(\u001b[43madj_orig\u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# actual value (0)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m preds_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([preds_pos, preds_neg])\n\u001b[1;32m     25\u001b[0m labels_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(preds_pos)), np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(preds_neg))])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:30\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 30\u001b[0m     index, new_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# 1D array\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:231\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     index_1st\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m isintlike(idx):\n\u001b[1;32m    232\u001b[0m     index_1st\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m    233\u001b[0m     prelim_ndim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "species = ['Homo sapiens','Mus musculus','Rattus norvegicus','Escherichia coli','Bos taurus','Pseudomonas aeruginosa','Arabidopsis thaliana','Saccharomyces cerevisiae','Drosophila melanogaster','Caenorhabditis elegans']\n",
    "seed_number = [12345, 22345, 32345, 42345, 52345]\n",
    "index = 0\n",
    "# saver = tf.train.Saver()\n",
    "result = {}\n",
    "for spcs in species[:1]:\n",
    "    spcs_temp = {}\n",
    "    for seed_num in seed_number:\n",
    "        print(spcs,seed_num)\n",
    "        # row = [[]]*len(list(result_charc))\n",
    "        mpi_file_name = './features/mpi_network/'+'mpi_'+str(spcs).replace(' ','_')+'.pkl'\n",
    "        df_file_name = './features/mpi_features/'+'feature_df_'+str(spcs).replace(' ','_')+'.pkl'\n",
    "        g = pickle.load(open(mpi_file_name, \"rb\" ))\n",
    "        node_feats = pd.read_pickle(df_file_name)\n",
    "        # node_feats = pickle.load(open(df_file_name, \"rb\" ))\n",
    "        features = np.stack(node_feats['features'].values, axis=0)\n",
    "        adj = nx.adjacency_matrix(g,nodelist=node_feats['node'].tolist())\n",
    "        # features = np.random.rand(adj.shape[0],1024)\n",
    "        adj_train, train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_seed(adj, test_frac=.1, val_frac=.1,seed=seed_num)\n",
    "        \n",
    "        x = sp.lil_matrix(features)\n",
    "        features_tuple = sparse_to_tuple(x)\n",
    "        features_shape = features_tuple[2]\n",
    "        # Get graph attributes (to feed into model)\n",
    "        num_nodes = adj.shape[0] # number of nodes in adjacency matrix\n",
    "        num_features = features_shape[1] # number of features (columsn of features matrix)\n",
    "        features_nonzero = features_tuple[1].shape[0] # number of non-zero entries in features matrix (or length of values list)\n",
    "        # Store original adjacency matrix (without diagonal entries) for later\n",
    "        adj_orig = adj\n",
    "        adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "        adj_orig.eliminate_zeros()\n",
    "        # Normalize adjacency matrix\n",
    "        adj_norm = preprocess_graph(adj_train)\n",
    "        # Add in diagonals\n",
    "        adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "        adj_label = sparse_to_tuple(adj_label)\n",
    "        cost_val = []\n",
    "        acc_val = []\n",
    "        val_roc_score = []\n",
    "        train_loss_log = []\n",
    "        val_loss_log = []\n",
    "        # Define hyperparameters\n",
    "        LEARNING_RATE = 0.005\n",
    "        EPOCHS = 500\n",
    "        HIDDEN1_DIM = 32\n",
    "        HIDDEN2_DIM = 16\n",
    "        DROPOUT = 0.1\n",
    "        # Define placeholders\n",
    "        placeholders = {\n",
    "            'features': tf.sparse_placeholder(tf.float32),\n",
    "            'adj': tf.sparse_placeholder(tf.float32),\n",
    "            'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "            'dropout': tf.placeholder_with_default(0., shape=())\n",
    "        }\n",
    "\n",
    "        # How much to weigh positive examples (true edges) in cost print_function\n",
    "        # Want to weigh less-frequent classes higher, so as to prevent model output bias\n",
    "        # pos_weight = (num. negative samples / (num. positive samples)\n",
    "        pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "\n",
    "        # normalize (scale) average weighted cost\n",
    "        norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "        # Create VAE model\n",
    "        model = GCNModelVAE(placeholders, num_features, num_nodes, features_nonzero, HIDDEN1_DIM, HIDDEN2_DIM)\n",
    "\n",
    "        opt = OptimizerVAE(preds=model.reconstructions,\n",
    "                                labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                            validate_indices=False), [-1]),\n",
    "                                model=model, num_nodes=num_nodes,\n",
    "                                pos_weight=pos_weight,\n",
    "                                norm=norm,\n",
    "                                learning_rate=LEARNING_RATE)\n",
    "\n",
    "        # Initialize session\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Train model\n",
    "        for epoch in range(EPOCHS):\n",
    "            t = time.time()\n",
    "            # Construct feed dictionary\n",
    "            feed_dict = construct_feed_dict(adj_norm, adj_label, features_tuple, placeholders)\n",
    "            feed_dict.update({placeholders['dropout']: DROPOUT})\n",
    "            # Run single weight update\n",
    "            outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_cost = outs[1]\n",
    "            avg_accuracy = outs[2]\n",
    "            roc_curr, ap_curr, fpr, tpr, pr_score, precision, recall = get_roc_score_vgae(train_edges, train_edges_false, pos_weight, norm)\n",
    "            # train_loss_log.append(train_loss_epoch)\n",
    "\n",
    "            # # Evaluate predictions\n",
    "            roc_curr, ap_curr, fpr, tpr, pr_score, precision, recall = get_roc_score_vgae(val_edges, val_edges_false, pos_weight, norm)\n",
    "            val_roc_score.append(roc_curr)\n",
    "            # val_loss_log.append(val_loss_epoch)\n",
    "            \n",
    "            if (epoch+1)%50 == 0:\n",
    "            # Print results for this epoch\n",
    "                print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "                    \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
    "                    \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "                    \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "                \n",
    "            # if (epoch+1) % 100 == 0:\n",
    "            #         saver.save(sess, './checkpoints/model', global_step=epoch+1)\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Print final results\n",
    "        feature_roc_score, feature_ap_score, feature_fpr, feature_tpr, feature_pr_score, feature_prcs, feature_rcal = get_roc_score_vgae(test_edges, test_edges_false, pos_weight, norm)\n",
    "        temp = [feature_roc_score, feature_ap_score, feature_fpr, feature_tpr, feature_pr_score, feature_prcs, feature_rcal]\n",
    "        print('Test ROC score: ' + str(feature_roc_score))\n",
    "        print('Test AP score: ' + str(feature_ap_score))\n",
    "        spcs_temp[seed_num] = temp\n",
    "    result[spcs] = spcs_temp\n",
    "pickle.dump(result,open('./graph_model_vgae_features.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n",
      "[]\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1172082/1958645489.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_gpu_available())  # TF 1.x method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:28:38.427401: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-28 23:28:38.479488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-28 23:28:38.479561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-28 23:28:38.480967: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-28 23:28:38.488472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-28 23:28:39.474296: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import tensorflow as tf; print(tf.test.is_built_with_cuda())\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n",
      "Built with CUDA: True\n",
      "GPU Available: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:36:58.676720: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:36:44.788627: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-28 23:36:44.846410: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-28 23:36:44.846466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-28 23:36:44.848031: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-28 23:36:44.856581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-28 23:36:45.965517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', '/usr/lib/llvm-17/bin/clang'), ('cuda_compute_capabilities', ['sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']), ('cuda_version', '12.2'), ('cudnn_version', '8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', True)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.sysconfig.get_build_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/lib64:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the environment variables are set in your current session\n",
    "#\n",
    "\n",
    "# # If not set, run these again before starting Jupyter:\n",
    "# !export LD_LIBRARY_PATH=/usr/local/cuda-12/lib64:$LD_LIBRARY_PATH\n",
    "# !export CUDA_HOME=/usr/local/cuda-12\n",
    "\n",
    "!echo $LD_LIBRARY_PATH\n",
    "!echo $CUDA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-12.4/lib64/libcudart.so\n",
      "/usr/local/cuda-12.4/lib64/libcudart.so.12\n",
      "/usr/local/cuda-12.4/lib64/libcudart.so.12.4.127\n",
      "/usr/local/cuda-12/lib64/libcudart.so\n",
      "/usr/local/cuda-12/lib64/libcudart.so.12\n",
      "/usr/local/cuda-12/lib64/libcudart.so.12.4.127\n",
      "/usr/local/cuda/lib64/libcudart.so\n",
      "/usr/local/cuda/lib64/libcudart.so.12\n",
      "/usr/local/cuda/lib64/libcudart.so.12.4.127\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local/cuda*/lib64/libcudart.so*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317.2146911621094px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
